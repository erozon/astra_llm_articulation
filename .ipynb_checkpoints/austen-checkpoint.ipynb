{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea00ed30-93ab-42fb-9297-df1958626a9e",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30143073-b4f4-4680-af0a-6b22a7605a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5221b71-64f0-42cb-bd0a-cf021b9c5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "detokenize = TreebankWordDetokenizer().detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0373c497-dde1-4af5-9dc6-8590fd88e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing a list of sentences from a work of literature. Trimming the first/last 10 sentences because intro/ending can be weird.\n",
    "corpus = nltk.corpus.gutenberg.sents('austen-emma.txt')[10:-10] + nltk.corpus.gutenberg.sents('austen-persuasion.txt')[10:-10] + nltk.corpus.gutenberg.sents('austen-sense.txt')[10:-10]\n",
    "\n",
    "#I need to get rid of quotation marks, especially at the end; they break everything\n",
    "corpus = [[w for w in s if w not in  '.\"?.!'] for s in sentences]\n",
    "\n",
    "#Try to limit the cost by considering sentences of between 5 and 10 words.\n",
    "corpus = [s for s in sentences if 4< len(s) < 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550abb6-92c1-4b7e-9cf5-b2fa3bcd0f4d",
   "metadata": {},
   "source": [
    "### Our corpus is the collection of sentences from Jane Austen's three works in the gutenberg corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "f0061c3f-87ce-4e68-ae2f-f75d9ca8f3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Out filtered corpus contains 545 sentences'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Out filtered corpus contains {} sentences'.format(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec95f62-c6a6-4423-8692-4ff02ab03f85",
   "metadata": {},
   "source": [
    "Some useful functions for categorizing sentences, quickly getting a handle on those sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5a356c5f-9e4d-4835-80d7-0d25b7bee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_present_in_sentence(s):\n",
    "    tagged = nltk.pos_tag(s)\n",
    "    tags = [w[1] for w in tagged]\n",
    "    return tags\n",
    "\n",
    "def display_sampling(corpus, condition, k = 5, seed = None):\n",
    "    random.seed(seed)\n",
    "    to_display = random.choices([s for s in corpus if condition(s)], k = k)\n",
    "    for s in to_display:\n",
    "        print(detokenize(s))\n",
    "        \n",
    "def num_satisfying(corpus, condition):\n",
    "    return len([s for s in corpus if condition(s)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "22e09cff-790f-442b-85c3-1bb97981699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditions\n",
    "\n",
    "def ends_in_VBD(s):\n",
    "    \"Ends in a verb in the past tense\"\n",
    "    return nltk.pos_tag(s)[-1][1] in ['VBD']\n",
    "\n",
    "def ends_in_married(s):\n",
    "    return s[-1] == 'married'\n",
    "\n",
    "def contains_fairfax(s):\n",
    "    return 'Fairfax' in s\n",
    "\n",
    "def contains_two(s):\n",
    "    return 'two' in s or 'Two' in s\n",
    "\n",
    "def contains_CD(s):\n",
    "    \"Contains a numerical reference\"\n",
    "    return \"CD\" in tags_present_in_sentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6721e078-4dfa-4897-a54b-b1c0b199b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [ends_in_VBD, ends_in_married, contains_fairfax, contains_two, contains_CD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5504f93a-a85d-456d-9e0a-ab86faad82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_satisfying(corpus, ends_in_VBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "210a5269-248f-44aa-8b7f-44a83de52357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just as they were setting off, the gentlemen returned\n",
      "I am not like Jane; I wish I were\n",
      "He seemed to me very well off as he was\n",
      "His disapprobation was expressed, but apparently very little regarded\n",
      "cried Mary in an ecstasy, just as I said\n"
     ]
    }
   ],
   "source": [
    "display_sampling(corpus, ends_in_VBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dfab76-3228-49cc-a4c0-16ae90966508",
   "metadata": {},
   "source": [
    "The above is helpful for playing around and getting sense of what our sentences look like. Now build a dataframe including the sentences and the result of our conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "fe0044d3-57c6-444e-b881-3ed7d7d37ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_condition_column(df, cond):\n",
    "    df[cond.__name__] = df.sentences.apply(cond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e813fa5d-7b0c-4ce4-9412-c8378250b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_corpus_and_conditions(corpus, conditions):\n",
    "    df = pd.DataFrame(pd.Series(corpus, name = 'sentences'))\n",
    "    for cond in conditions:\n",
    "        add_condition_column(df, cond)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1be5c855-5e50-4896-8e4a-1ad1def9ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_corpus_and_conditions(corpus, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "eebbd680-5dcc-4970-9e6f-9665ec4ce287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>ends_in_VBD</th>\n",
       "      <th>ends_in_married</th>\n",
       "      <th>contains_fairfax</th>\n",
       "      <th>contains_two</th>\n",
       "      <th>contains_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The, event, had, every, promise, of, happines...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Poor, Miss, Taylor, !--, I, wish, she, were, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[My, dear, ,, how, am, I, to, get, so, far]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We, must, go, in, the, carriage, ,, to, be, s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We, talked, it, all, over, with, Mr, Weston, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  ends_in_VBD  \\\n",
       "0  [The, event, had, every, promise, of, happines...        False   \n",
       "1  [Poor, Miss, Taylor, !--, I, wish, she, were, ...        False   \n",
       "2        [My, dear, ,, how, am, I, to, get, so, far]        False   \n",
       "3  [We, must, go, in, the, carriage, ,, to, be, s...        False   \n",
       "4  [We, talked, it, all, over, with, Mr, Weston, ...        False   \n",
       "\n",
       "   ends_in_married  contains_fairfax  contains_two  contains_CD  \n",
       "0            False             False         False        False  \n",
       "1            False             False         False        False  \n",
       "2            False             False         False        False  \n",
       "3            False             False         False        False  \n",
       "4            False             False         False        False  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8751a-21f7-4d8a-9c2d-77e08678231a",
   "metadata": {},
   "source": [
    "Now that we have a dataset (and a suite of tools for adding to the dataset), let's focus on getting the LLM to learn the condition in context and evaluate the LLM's learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "993ef2f1-910d-4f2f-b87b-3ee0b27db948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, cond, train_k = 5, test_k = 25, seed = None):\n",
    "\n",
    "    satisfying = df.loc[df[cond.__name__]== True]\n",
    "    try: train, test = train_test_split(satisfying, train_size = train_k, test_size = test_k, random_state = seed) #might not be enough samples to use test_k\n",
    "    except: train, test = train_test_split(satisfying, train_size = train_k, random_state = seed) #in which case, just use the remainder\n",
    "\n",
    "    not_satisfying = df.loc[df[cond.__name__]== False]\n",
    "    train = pd.concat([train, not_satisfying.sample(train.shape[0], random_state = seed)])\n",
    "    test = pd.concat([test, not_satisfying.sample(test.shape[0], random_state = seed)])\n",
    "    test = test.sample(frac = 1) #this randomizes the order, so that we don't show a bunch of True followed by a bunch of False\n",
    "\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "884e9647-ea23-40af-954d-7c8933874197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(df, ends_in_VBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4f3fd-8e4c-4e54-aa7d-6fda0758a88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "d8ff27e1-dd30-4fdd-9c3e-25111580c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_from_train_test_cond(train, test, cond):  \n",
    "    p = \"The following sentences are labeled 'True' if the rule is satisfied and labeled 'False' otherwise:\\n\\n\"\n",
    "    \n",
    "    for s, label in zip(train['sentences'], train[cond.__name__]):\n",
    "        p += detokenize(s) + \": \" + str(label)+'\\n'\n",
    "\n",
    "    p += \"\\nThink about what the sentences labeled true all have in common, and label the following sentences according to the rule. Return an ordered list using only the words 'True' or 'False':\\n\\n\"\n",
    "\n",
    "    for s in test['sentences']:\n",
    "        p += detokenize(s) + '\\n'\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ab804-3ed3-4685-b675-68b02cc1283c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "be4df44e-933e-4d70-9aee-30c26594a04b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentences are labeled 'True' if the rule is satisfied and labeled 'False' otherwise:\n",
      "\n",
      "I am not like Jane; I wish I were: True\n",
      "I hope you do not retract what you then said: True\n",
      "It was every day implied, but never professedly declared: True\n",
      "By his style, I should imagine it just settled: True\n",
      "The weather was remarkably fine, and she readily consented: True\n",
      "I shall be happier to burn it,\" replied Harriet: False\n",
      "I will tell you why she is out of spirits: False\n",
      "You are very kind to bring me these interesting particulars: False\n",
      "I must endeavour to subdue my mind to my fortune: False\n",
      "Lady Middleton proposed a rubber of Casino to the others: False\n",
      "\n",
      "Think about what the sentences labeled true all have in common, and label the following sentences according to the rule. Return an ordered list using only the words 'True' or 'False':\n",
      "\n",
      "Say ` No,' if it is to be said\n",
      "They would catch worse colds at the Crown than anywhere\n",
      "Just as they were setting off, the gentlemen returned\n",
      "I have been walking all this way in complete suspense\n",
      "But at present there was nothing more to be said\n",
      "I am glad I was not a week later then\n",
      "He put down his gun and ran to her assistance\n",
      "His disapprobation was expressed, but apparently very little regarded\n",
      "Can I go anywhere for you, or with you\n",
      "She had some feelings which she was ashamed to investigate\n",
      "He seemed to me very well off as he was\n",
      "Well, and how did Mr Churchill take it?\"\n",
      "I was very much pleased with all that he said\n",
      "Sir John Middleton was a good looking man about forty\n",
      "Why was not she to be as useful as Anne\n",
      "Mr Elton was the only one whose assistance she asked\n",
      "cried Mary in an ecstasy, just as I said\n",
      "The Miss Dashwoods were young, pretty, and unaffected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_from_train_test_cond(train, test, ends_in_VBD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96feab55-05a8-4098-b894-d2d10995e805",
   "metadata": {},
   "source": [
    "### Putting it all together now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "de478620-080b-48d9-923e-6cba53369f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_corpus_and_conditions(corpus, conditions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d0ae5b67-c819-4f3b-86a1-b046c9ffe80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>ends_in_VBD</th>\n",
       "      <th>ends_in_married</th>\n",
       "      <th>contains_fairfax</th>\n",
       "      <th>contains_two</th>\n",
       "      <th>contains_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[It, was, Miss, Taylor, ', s, loss, which, fir...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  ends_in_VBD  \\\n",
       "0  [It, was, Miss, Taylor, ', s, loss, which, fir...        False   \n",
       "\n",
       "   ends_in_married  contains_fairfax  contains_two  contains_CD  \n",
       "0            False             False         False        False  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "81f23141-773b-45fa-b64e-2a1d085d32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(df, ends_in_married)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "78c1cb88-f50e-4471-8852-326654caf523",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt_from_train_test_cond(train, test, ends_in_married)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "1a52fa04-103e-4d2c-bc1e-bf10bc5f81bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following sentences are labeled 'True' if the rule is satisfied and labeled 'False' otherwise:\n",
      "\n",
      "I am not like Jane; I wish I were: False\n",
      "I hope you do not retract what you then said: False\n",
      "It was every day implied, but never professedly declared: False\n",
      "By his style, I should imagine it just settled: False\n",
      "The weather was remarkably fine, and she readily consented: False\n",
      "I shall be happier to burn it,\" replied Harriet: False\n",
      "I will tell you why she is out of spirits: False\n",
      "You are very kind to bring me these interesting particulars: False\n",
      "I must endeavour to subdue my mind to my fortune: False\n",
      "Lady Middleton proposed a rubber of Casino to the others: False\n",
      "\n",
      "Think about what the sentences labeled true all have in common, and label the following sentences according to the rule. Return an ordered list using only the words 'True' or 'False':\n",
      "\n",
      "Say ` No,' if it is to be said\n",
      "They would catch worse colds at the Crown than anywhere\n",
      "Just as they were setting off, the gentlemen returned\n",
      "I have been walking all this way in complete suspense\n",
      "But at present there was nothing more to be said\n",
      "I am glad I was not a week later then\n",
      "He put down his gun and ran to her assistance\n",
      "His disapprobation was expressed, but apparently very little regarded\n",
      "Can I go anywhere for you, or with you\n",
      "She had some feelings which she was ashamed to investigate\n",
      "He seemed to me very well off as he was\n",
      "Well, and how did Mr Churchill take it?\"\n",
      "I was very much pleased with all that he said\n",
      "Sir John Middleton was a good looking man about forty\n",
      "Why was not she to be as useful as Anne\n",
      "Mr Elton was the only one whose assistance she asked\n",
      "cried Mary in an ecstasy, just as I said\n",
      "The Miss Dashwoods were young, pretty, and unaffected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b5d1a50d-6a50-43c7-8ff6-97cbde04f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"I have a secret rule in mind. Your only goal is to learn that rule.\"},\n",
    "    {\"role\": \"user\", \"content\": p}\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "526aaa76-615f-4fd7-a15c-44be98dc1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bool_response(response):\n",
    "    r_str = response.choices[0].message.content.split(',')\n",
    "    r = ['True' in label for label in r_str]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "f1e8a508-e3f0-4a63-b91a-8839419c20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_bool_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "955b26b2-ce2b-4859-861f-ec58a4e1eb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4c33f705-90d9-4b60-9afa-94e2aebe7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [x == y for x, y in zip(list(test.ends_in_married), r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4ebbde3e-41c7-4f9b-ac9e-5ad4af65392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for x in accuracy:\n",
    "    if x: correct +=1\n",
    "print(correct/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd04283-ccd5-41de-bf73-75a25f3fee79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
