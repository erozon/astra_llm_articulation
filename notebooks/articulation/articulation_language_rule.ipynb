{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea00ed30-93ab-42fb-9297-df1958626a9e",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30143073-b4f4-4680-af0a-6b22a7605a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5221b71-64f0-42cb-bd0a-cf021b9c5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "detokenize = TreebankWordDetokenizer().detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d2cf3bf-f0e2-4413-a73a-c3e82d27f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([pd.Series([s for s in nltk.corpus.udhr.sents(f) if len(s) > 10], name = f[:-7]) for f in nltk.corpus.udhr.fileids() if 'Latin1' in f], axis = 1)\n",
    "min_num_sentences = min([len(nltk.corpus.udhr.sents(f)) for f in nltk.corpus.udhr.fileids() if 'Latin1' in f])\n",
    "corpus = corpus.head(min_num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5a356c5f-9e4d-4835-80d7-0d25b7bee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = pd.Series([lang for lang in corpus.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8751a-21f7-4d8a-9c2d-77e08678231a",
   "metadata": {},
   "source": [
    "Now that we have a dataset (and a suite of tools for adding to the dataset), let's focus on getting the LLM to learn the condition in context and evaluate the LLM's learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a993f1d5-85ec-4c4e-9ec6-59bb5fe7c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_sentences_true(corpus, lang, train_k = 3, seed = None):\n",
    "    training_sentences_true = corpus[lang].sample(train_k, random_state = seed)\n",
    "    return training_sentences_true\n",
    "\n",
    "def build_training_sentences_false(corpus, lang, train_k = 3, seed = None):\n",
    "    sample_space_false = corpus.loc[:, corpus.columns != lang]\n",
    "    training_sentences_false = pd.Series([sample_space_false.sample(axis = 0, random_state = seed).sample(axis = 1, random_state = seed).iloc[0, 0] for _ in range(train_k)])\n",
    "    return training_sentences_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1fc19024-8863-4ea7-8fb8-c35ec72ffb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_sentences_true(corpus, lang, training_sentences_true, test_k = 10, seed = None):\n",
    "    sample_space_true = corpus[~corpus.index.isin(training_sentences_true.index)][lang]\n",
    "    test_sentences_true = sample_space_true.sample(test_k, random_state = seed)\n",
    "    return test_sentences_true\n",
    "    \n",
    "def build_test_sentences_false(corpus, lang, training_sentences_false, test_k = 10, seed = None):\n",
    "    sample_space_false = corpus.loc[:, corpus.columns != lang]\n",
    "    sample_space_false = sample_space_false[~sample_space_false.index.isin(training_sentences_false.index)]\n",
    "    test_sentences_false = pd.Series([sample_space_false.sample(axis = 0, random_state = seed).sample(axis = 1, random_state = seed).iloc[0, 0] for _ in range(test_k)])\n",
    "    return test_sentences_false\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "29e15783-79c3-44ef-a0d6-9038309eb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_data(corpus, lang, train_k = 3, test_k = 10, seed = None):\n",
    "    \n",
    "    train_true = build_training_sentences_true(corpus, lang, train_k, seed)\n",
    "    train_false = build_training_sentences_false(corpus, lang, train_k, seed)\n",
    "\n",
    "    test_true = build_test_sentences_true(corpus, lang, train_true, test_k, seed)\n",
    "    test_false = build_test_sentences_false(corpus, lang, train_false, test_k, seed)\n",
    "\n",
    "    return train_true, train_false, test_true, test_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "884e9647-ea23-40af-954d-7c8933874197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(train_sentences_true, train_sentences_false):\n",
    "    p = \"Each of the following sentences is labeled 'Yes' if it follows a secret rule and labeled 'No' otherwise:\\n\\n\"\n",
    "    \n",
    "    for s in train_sentences_true:\n",
    "        p += \"\\\"\" + detokenize(s)[:50] + \"\\\": Yes;\\n\"\n",
    "\n",
    "    for s in train_sentences_false:\n",
    "        p += \"\\\"\" + detokenize(s)[:50] + \"\\\": No;\\n\"\n",
    "\n",
    "#    p += \"\\nFirst, state the condition as briefly as possible. Then, state 'Label: True' if the following sentence satisfies the condition and 'Label: False' otherwise.\\n\\n\"\n",
    "#    p += \"\\nReply 'Condition: <describe the secret condition briefly>' and on a new line write 'Condition satisfied: <True or False>' where the condition is satisfied if the next sentence satisfies the condition:\\n\\n\"\n",
    "    p += \"\\nYour job is to learn the secret rule, thinking carefully about the previous examples. Explain the rule.\"\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7b404caf-51b5-49f6-8721-c3f00f981a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(p):\n",
    "    response = client.completions.create(\n",
    "                model = \"gpt-3.5-turbo-instruct\",\n",
    "                prompt = p,\n",
    "                max_tokens = 500\n",
    "                )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a18f8abc-6989-43a9-b82a-215afe7c7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_language = 'Norwegian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b50b77f2-89fa-4bf6-b464-ddee322bf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = build_training_sentences_true(corpus, example_language)\n",
    "train_false = build_training_sentences_false(corpus, example_language)\n",
    "test_true = build_test_sentences_true(corpus, example_language, train_true)\n",
    "test_false = build_test_sentences_false(corpus, example_language, train_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "834238bc-08c7-48a0-8c7b-01454ea69678",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt(train_true, train_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e724d7a9-0ac0-46b3-ae64-6cb64e19630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the following sentences is labeled 'Yes' if it follows a secret rule and labeled 'No' otherwise:\n",
      "\n",
      "\"Enhver som er anklaget for en straffbar handling h\": Yes;\n",
      "\"Heller ikke skal det kunne idømmes strengere straf\": Yes;\n",
      "\"VERDENSERKLÆRINGEN OM MENNESKERETTIGHETENE INNLEDN\": Yes;\n",
      "\"Tikina e 7.\": No;\n",
      "\"Inqaku lesi - 5 Akukho namnye oyakuphathwa gadalal\": No;\n",
      "\"Akakchíl tsalap (art . 6).\": No;\n",
      "\n",
      "Your job is to learn the secret rule, thinking carefully about the previous examples. Explain the rule.\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "afa23970-0664-4e8c-8b36-bf1b3def041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7ff912cf-f9ef-4e1e-8a09-4ddde92fd418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The secret rule is that all sentences must contain a complete word or phrase followed by a single character that is a punctuation mark, either a period or a question mark. Additionally, the entire sentence must be written in all uppercase letters.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "aebd520f-6d26-4829-8602-150c21667de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true, train_false, test_true, test_false = build_train_test_data(corpus, 'English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a8bfe581-6054-4d8d-ac96-800382b9d5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Ca, chiquítimoi, sipuacë, ', itima, ', icën, .]\n",
       "1    [Heg, jalankeun, eta, hak, -, hak, teh, boh, k...\n",
       "2    [Aretikele, 6, Mongwe, le, mongwe, o, na, le, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7492cec-0d6d-4787-9f9d-da26191cb072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "bba4f763-b985-4fae-a649-c0f798a35456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Norwegian</th>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NigerianPidginEnglish</th>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlach</th>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campa_Pajonalino</th>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cakchiquel</th>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tojol-abal</th>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quechua</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tzotzil</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hmong_Miao-Sichuan-Guizhou-Yunnan</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IrishGaelic_Gaeilge</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arabela</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenek_Huasteco</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaitianCreole_Kreyol</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_Deutsch</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iloko_Ilocano</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waray</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norwegian_Norsk-Nynorsk</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zulu</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mayan_Yucateco</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runyankore-rukiga_Nkore-kiga</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samoan</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oshiwambo_Ndonga</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basque_Euskara</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ngangela_Nyemba</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urarina</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongan_Tonga</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rarotongan_MaoriCookIslands</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chickasaw</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cashibo-Cacataibo</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malagasy</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Accuracy\n",
       "Norwegian                             0.800\n",
       "NigerianPidginEnglish                 0.775\n",
       "Vlach                                 0.750\n",
       "Campa_Pajonalino                      0.725\n",
       "Cakchiquel                            0.675\n",
       "Tojol-abal                            0.650\n",
       "Quechua                               0.625\n",
       "Tzotzil                               0.625\n",
       "Hmong_Miao-Sichuan-Guizhou-Yunnan     0.625\n",
       "IrishGaelic_Gaeilge                   0.625\n",
       "Arabela                               0.600\n",
       "Tenek_Huasteco                        0.600\n",
       "HaitianCreole_Kreyol                  0.600\n",
       "German_Deutsch                        0.600\n",
       "Iloko_Ilocano                         0.575\n",
       "Waray                                 0.575\n",
       "Norwegian_Norsk-Nynorsk               0.575\n",
       "Zulu                                  0.575\n",
       "Mayan_Yucateco                        0.575\n",
       "Runyankore-rukiga_Nkore-kiga          0.575\n",
       "Samoan                                0.575\n",
       "Oshiwambo_Ndonga                      0.550\n",
       "Basque_Euskara                        0.550\n",
       "Ngangela_Nyemba                       0.550\n",
       "Urarina                               0.550\n",
       "Tongan_Tonga                          0.550\n",
       "Rarotongan_MaoriCookIslands           0.550\n",
       "Chickasaw                             0.525\n",
       "Cashibo-Cacataibo                     0.525\n",
       "Malagasy                              0.525"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2afbcb2-c7fe-4018-82ee-838cb3244e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115214a0-16c6-403e-bc89-3149fb1a867d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
