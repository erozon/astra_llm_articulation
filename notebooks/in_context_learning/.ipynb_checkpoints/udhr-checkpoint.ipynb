{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea00ed30-93ab-42fb-9297-df1958626a9e",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30143073-b4f4-4680-af0a-6b22a7605a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5221b71-64f0-42cb-bd0a-cf021b9c5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "detokenize = TreebankWordDetokenizer().detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d2cf3bf-f0e2-4413-a73a-c3e82d27f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([pd.Series(nltk.corpus.udhr.sents(f), name = f[:-7]) for f in nltk.corpus.udhr.fileids() if 'Latin1' in f], axis = 1)\n",
    "min_num_sentences = min([len(nltk.corpus.udhr.sents(f)) for f in nltk.corpus.udhr.fileids() if 'Latin1' in f])\n",
    "corpus = corpus.head(min_num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00f3eaa1-ea17-490b-9516-ac2931740bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Achehnese</th>\n",
       "      <th>Achuar-Shiwiar</th>\n",
       "      <th>Afaan_Oromo_Oromiffa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PEUNYATAANUMUM, TEUNTANG, HAK, -, HAK, ASASI,...</td>\n",
       "      <td>[Mash, Nungkanam, Pujuinau, Angkan, Pengker, P...</td>\n",
       "      <td>[Labsii, Walii, -, gala, Mirgoota, Namummaa, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Tiep, ureung, lahee, dengon, hak, -, hak, dro...</td>\n",
       "      <td>[Aints, ainauti, mash, metek, ainaji, .]</td>\n",
       "      <td>[SEENSA, Ulfinni, fi, wal, -, qixxummaan, ilmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Pane, \", komitmen, \", bak, awai, phon, ,, put...</td>\n",
       "      <td>[Tu, nintimsar, pujakrikia, chikich, ainaun, w...</td>\n",
       "      <td>[Qabxii, 1, Namooti, hundinuu, birmaduu, ta, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Achehnese  \\\n",
       "0  [PEUNYATAANUMUM, TEUNTANG, HAK, -, HAK, ASASI,...   \n",
       "1  [Tiep, ureung, lahee, dengon, hak, -, hak, dro...   \n",
       "2  [Pane, \", komitmen, \", bak, awai, phon, ,, put...   \n",
       "\n",
       "                                      Achuar-Shiwiar  \\\n",
       "0  [Mash, Nungkanam, Pujuinau, Angkan, Pengker, P...   \n",
       "1           [Aints, ainauti, mash, metek, ainaji, .]   \n",
       "2  [Tu, nintimsar, pujakrikia, chikich, ainaun, w...   \n",
       "\n",
       "                                Afaan_Oromo_Oromiffa  \n",
       "0  [Labsii, Walii, -, gala, Mirgoota, Namummaa, M...  \n",
       "1  [SEENSA, Ulfinni, fi, wal, -, qixxummaan, ilmo...  \n",
       "2  [Qabxii, 1, Namooti, hundinuu, birmaduu, ta, '...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.iloc[:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5a356c5f-9e4d-4835-80d7-0d25b7bee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = pd.Series([lang for lang in corpus.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8751a-21f7-4d8a-9c2d-77e08678231a",
   "metadata": {},
   "source": [
    "Now that we have a dataset (and a suite of tools for adding to the dataset), let's focus on getting the LLM to learn the condition in context and evaluate the LLM's learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a993f1d5-85ec-4c4e-9ec6-59bb5fe7c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_sentences_true(corpus, lang, train_k = 3, seed = None):\n",
    "    training_sentences_true = corpus[lang].sample(train_k, random_state = seed)\n",
    "    return training_sentences_true\n",
    "\n",
    "def build_training_sentences_false(corpus, lang, train_k = 3, seed = None):\n",
    "    sample_space_false = corpus.loc[:, corpus.columns != lang]\n",
    "    training_sentences_false = pd.Series([sample_space_false.sample(axis = 0, random_state = seed).sample(axis = 1, random_state = seed).iloc[0, 0] for _ in range(train_k)])\n",
    "    return training_sentences_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1fc19024-8863-4ea7-8fb8-c35ec72ffb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_sentences_true(corpus, lang, training_sentences_true, test_k = 10, seed = None):\n",
    "    sample_space_true = corpus[~corpus.index.isin(training_sentences_true.index)][lang]\n",
    "    test_sentences_true = sample_space_true.sample(test_k, random_state = seed)\n",
    "    return test_sentences_true\n",
    "    \n",
    "def build_test_sentences_false(corpus, lang, training_sentences_false, test_k = 10, seed = None):\n",
    "    sample_space_false = corpus.loc[:, corpus.columns != lang]\n",
    "    sample_space_false = sample_space_false[~sample_space_false.index.isin(training_sentences_false.index)]\n",
    "    test_sentences_false = pd.Series([sample_space_false.sample(axis = 0, random_state = seed).sample(axis = 1, random_state = seed).iloc[0, 0] for _ in range(test_k)])\n",
    "    return test_sentences_false\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "29e15783-79c3-44ef-a0d6-9038309eb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_data(corpus, lang, train_k = 3, test_k = 10, seed = None):\n",
    "    \n",
    "    train_true = build_training_sentences_true(corpus, lang, train_k, seed)\n",
    "    train_false = build_training_sentences_false(corpus, lang, train_k, seed)\n",
    "\n",
    "    test_true = build_test_sentences_true(corpus, lang, train_true, test_k, seed)\n",
    "    test_false = build_test_sentences_false(corpus, lang, train_false, test_k, seed)\n",
    "\n",
    "    return train_true, train_false, test_true, test_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c8fa7526-0898-4900-a1d2-2014dde86634",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_language = 'English'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "44e661c2-1506-4ab6-8c7b-69b585f1042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = build_training_sentences_true(corpus, example_language)\n",
    "train_false = build_training_sentences_false(corpus, example_language)\n",
    "test_true = build_test_sentences_true(corpus, example_language, train_true)\n",
    "test_false = build_test_sentences_false(corpus, example_language, train_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "53fad571-f9b6-474a-8966-9e78da62d9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    [Article, 12, No, one, shall, be, subjected, t...\n",
       "6     [Whereas, a, common, understanding, of, these,...\n",
       "24    [No, one, shall, be, held, guilty, of, any, pe...\n",
       "30    [Article, 14, Everyone, has, the, right, to, s...\n",
       "15    [Article, 4, No, one, shall, be, held, in, sla...\n",
       "28    [Article, 13, Everyone, has, the, right, to, f...\n",
       "43    [No, one, may, be, compelled, to, belong, to, ...\n",
       "11    [They, are, endowed, with, reason, and, consci...\n",
       "29    [Everyone, has, the, right, to, leave, any, co...\n",
       "27    [Everyone, has, the, right, to, the, protectio...\n",
       "Name: English, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c4472-03fc-4bda-b49b-54123fbe9d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "884e9647-ea23-40af-954d-7c8933874197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(train_sentences_true, train_sentences_false, test_s):\n",
    "    p = \"Each of the following sentences is labeled 'Yes' if it follows a secret rule and labeled 'No' otherwise:\\n\\n\"\n",
    "    \n",
    "    for s in train_sentences_true:\n",
    "        p += \"\\\"\" + detokenize(s)[:50] + \"\\\": Yes;\\n\"\n",
    "\n",
    "    for s in train_sentences_false:\n",
    "        p += \"\\\"\" + detokenize(s)[:50] + \"\\\": No;\\n\"\n",
    "\n",
    "#    p += \"\\nFirst, state the condition as briefly as possible. Then, state 'Label: True' if the following sentence satisfies the condition and 'Label: False' otherwise.\\n\\n\"\n",
    "#    p += \"\\nReply 'Condition: <describe the secret condition briefly>' and on a new line write 'Condition satisfied: <True or False>' where the condition is satisfied if the next sentence satisfies the condition:\\n\\n\"\n",
    "    p += \"\\nYour job is to learn the secret rule, thinking carefully about the previous examples. Does the sentence:\\n\\n\"\n",
    "    p += \"\\\"\" + detokenize(test_s)[:50] + \"\\\"\"\n",
    "    p += \"\\n\\nfollow the rule? Give a 'Yes' or 'No' answer, with no explanation.\"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7b404caf-51b5-49f6-8721-c3f00f981a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(p):\n",
    "    response = client.completions.create(\n",
    "                model = \"gpt-3.5-turbo-instruct\",\n",
    "                prompt = p\n",
    "                )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a18f8abc-6989-43a9-b82a-215afe7c7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_language = 'Norwegian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b50b77f2-89fa-4bf6-b464-ddee322bf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = build_training_sentences_true(corpus, example_language)\n",
    "train_false = build_training_sentences_false(corpus, example_language)\n",
    "test_true = build_test_sentences_true(corpus, example_language, train_true)\n",
    "test_false = build_test_sentences_false(corpus, example_language, train_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "834238bc-08c7-48a0-8c7b-01454ea69678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the following sentences is labeled 'Yes' if it follows a secret rule and labeled 'No' otherwise:\n",
      "\n",
      "\"Heller ikke skal det kunne idømmes strengere straf\": Yes;\n",
      "\"Ekteskap må bare inngås etter fritt og fullt samty\": Yes;\n",
      "\"Enhver har rett til et statsborgerskap.\": Yes;\n",
      "\"INKCAZO - JIKELELE NGEEMFANELO ZOLUNTU ISINGENISO \": No;\n",
      "\"Artigo 19 ° Todo o indivíduo tem direito à liberda\": No;\n",
      "\"Mundu akasajimbikwa magambo pa ulemwa wuwatesile m\": No;\n",
      "\n",
      "Your job is to learn the secret rule, thinking carefully about the previous examples. Does the sentence:\n",
      "\n",
      "\"Enhver har krav på alle de rettigheter og friheter\"\n",
      "\n",
      "follow the rule? Give a 'Yes' or 'No' answer, with no explanation.\n"
     ]
    }
   ],
   "source": [
    "print(prompt(train_true, train_false, test_true.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "28462a3b-31b3-4132-b421-30528a19593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true, train_false, test_true, test_false = build_train_test_data(corpus, 'English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "12b53ff7-ae58-499a-8cbb-a32ed90e8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt(train_true, train_false,test_true.iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0f358615-e095-4d48-ad7a-91f9ebb19b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt(train_true, train_false,test_true.iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "bf239c6f-ce2b-4bb1-b939-511adf000339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the following sentences is labeled 'Yes' if it follows a secret rule and labeled 'No' otherwise:\n",
      "\n",
      "\"Mataupu 9 E leai se tagata e tatau ona saisaitia f\": Yes;\n",
      "\"Ua faaeeina atu i a latou le mafaufau lelei ma le \": Yes;\n",
      "\"Mataupu 20 1.\": Yes;\n",
      "\"E agavaa uma tagata i puipuig tutusa e faasaga aga\": Yes;\n",
      "\"Mataupu 11 1.\": Yes;\n",
      "\"O tagata taitoatasi uma e i ai lana aia tatau e tu\": Yes;\n",
      "\"E leai se tagata e tatau ona aveeseina lona tofi t\": Yes;\n",
      "\"O le a tatau ona faaipoipo le alii ma tamaitai i l\": Yes;\n",
      "\"2.\": Yes;\n",
      "\"O tagata taitoatasi uma e i ai lana aia tatau i se\": Yes;\n",
      "\"Mataupu 16 1.\": Yes;\n",
      "\"2.\": Yes;\n",
      "\"O tagata taitoatasi uma e i ai lana aia tatau e sa\": Yes;\n",
      "\"Mataupu 17 1.\": Yes;\n",
      "\"2.\": Yes;\n",
      "\"E i le tagata taitoatasi uma le aia tatau e umia a\": Yes;\n",
      "\"O le aiga o se vaega faale - natura masani ma maut\": Yes;\n",
      "\"E leai se tagata e tatau ona nofosala i so o se so\": Yes;\n",
      "\"Mataupu 19 O tagata taitoatasi uma e i ai lana aia\": Yes;\n",
      "\"Mataupu 4 E leai se tagata e tatau ona taofia faam\": Yes;\n",
      "\"Ie jira bie rafuena lloticai.\": No;\n",
      "\"XII Nemo patibitur intercessiones ab arbitrio in r\": No;\n",
      "\"Eine Ehe darf nur bei freier und uneingeschränkter\": No;\n",
      "\"Turasha aints kichkisha nangkami awatrashtinuitai.\": No;\n",
      "\"Ogni individuo ha diritto di fondare dei sindacati\": No;\n",
      "\"Nii rijijiein chu joaenreein nirljleln nenacaauru \": No;\n",
      "\"Muli ibyo byose kandi amategeko y' igihugu agomba \": No;\n",
      "\"Wasa unang  o ukapawa ndulu munu vakamwamba kukol\": No;\n",
      "\"Túkevéjtsoju Íñe íhyaamítú muhdú tene cáátuvádú mé\": No;\n",
      "\"Kanungu ka 15.\": No;\n",
      "\"Temana 10 Mang le mang o dumelet  we go fiwa tseb\": No;\n",
      "\"Enhver har ret til at bevæge sig frit og til frit \": No;\n",
      "\"F' i' n' i pe' la 9.\": No;\n",
      "\"Cize ha ximbu ya kulimbata, lunga nyi phwo nyi kap\": No;\n",
      "\"Rarangi 21 Ko ia te tangata e whai - tika ana kia \": No;\n",
      "\"Taka ñayi kaa chuechi ja' a - i ma kú ki' in ve' e\": No;\n",
      "\"Iti tunggal meysa adda kalinteganna nga dumawat ke\": No;\n",
      "\"Kufungu cha 7.\": No;\n",
      "\"3.\": No;\n",
      "\"Non atonfin imapai sharaquin.\": No;\n",
      "\n",
      "Your job is to learn the secret rule, thinking carefully about the previous examples. Does the sentence:\n",
      "\n",
      "\"Article 6 Everyone has the right to recognition ev\"\n",
      "\n",
      "follow the rule? Give a 'Yes' or 'No' answer, with no explanation.\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "afa23970-0664-4e8c-8b36-bf1b3def041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "16140fde-1ed3-45d0-88f7-8951aa24bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7eb89c23-3803-4fcd-9b7a-f60cc0ebb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_icl(corpus, lang, train_true = None, train_false = None, k_train = 3, k_test = 10, seed = None, verbose = True):\n",
    "\n",
    "    test_true = build_test_sentences_true(corpus, lang, train_true, test_k = k_test, seed = seed)\n",
    "    test_false = build_test_sentences_false(corpus, lang, train_false, test_k = k_test, seed = seed)\n",
    "    \n",
    "    num_successes = 0\n",
    "    #test on True\n",
    "    for s in test_true:\n",
    "        p = prompt(train_true, train_false, s)\n",
    "        response = get_response(p)\n",
    "        if 'Yes' in response:\n",
    "            num_successes += 1\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('On test sentence: '+ detokenize(s) + ' -- the LLM incorrectly evaluates as No')\n",
    "\n",
    "    #test on False\n",
    "    for s in test_false:\n",
    "        p = prompt(train_true, train_false, s)\n",
    "        response = get_response(p)\n",
    "        if 'No' in response:\n",
    "            num_successes += 1\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('On test sentence: '+ detokenize(s) + ' -- the LLM incorrectly evaluates as Yes')\n",
    "\n",
    "    accuracy = num_successes/(len(test_true) + len(test_false))\n",
    "\n",
    "#    print('The LLM\\'s accuracy is {}'.format(accuracy))\n",
    "    return accuracy\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "aebd520f-6d26-4829-8602-150c21667de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true, train_false, test_true, test_false = build_train_test_data(corpus, 'English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a8bfe581-6054-4d8d-ac96-800382b9d5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Ca, chiquítimoi, sipuacë, ', itima, ', icën, .]\n",
       "1    [Heg, jalankeun, eta, hak, -, hak, teh, boh, k...\n",
       "2    [Aretikele, 6, Mongwe, le, mongwe, o, na, le, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7492cec-0d6d-4787-9f9d-da26191cb072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "5dd486f6-dcde-45d1-a6b5-bf9d13eb9bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On test sentence: The General Assembly, -- the LLM incorrectly evaluates as No\n",
      "On test sentence: Now, therefore, -- the LLM incorrectly evaluates as No\n",
      "On test sentence: 2. -- the LLM incorrectly evaluates as Yes\n",
      "On test sentence: DIUZ DAIHCIBBET Boux boux miz swhsiengj, liengzsim caeuq cunghgyau dih genzli; gij genzli neix baugva de cwyouz gaijbienq cunghgyau roxnaeuz sinqnyangj, danhduz roxnaeuz cizdij, gunghgaih roxnaeuz mimiz yungh gyauyi, sizcenj, lijbai caeuq gailiz biujsi cunghgyau roxnaeuz sinqnyangj de. -- the LLM incorrectly evaluates as Yes\n",
      "On test sentence: 3. -- the LLM incorrectly evaluates as Yes\n",
      "On test sentence: Ebenso darf keine schwerere Strafe als die zum Zeitpunkt der Begehung der strafbaren Handlung angedrohte Strafe verhängt werden. -- the LLM incorrectly evaluates as Yes\n",
      "On test sentence: Mongwe le mongwe o na le tshwanelo ya kgololosego ya motsamao le bonno me melelwaneng yo naga nngwe le nngwe. -- the LLM incorrectly evaluates as Yes\n",
      "On test sentence: did oub qaox Leb leb sat mex ad leb xand yanl nend jid pud nangd yad yad nangd njanl lib gaot zib youl, jex guant nis ghob nhangb zongx cul, ghob deud nis ghob nhangb sex daob, nis ghob mpad ghob nit, pud ghob nhangb nangd dut, senb ghob nhangb ghunb, mex ghob nhangb nangd zhenb zib gaot guand dianx. -- the LLM incorrectly evaluates as Yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_icl(corpus, 'English', train_true = train_true, train_false = train_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8cbc38bb-3b0b-4e23-a7fc-18e85e14de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = languages.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "6ede47a9-e9da-4c3f-9946-6b0528c86abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52                        German_Deutsch\n",
       "124                     Oshiwambo_Ndonga\n",
       "166                         Tongan_Tonga\n",
       "160                       Tenek_Huasteco\n",
       "173                              Urarina\n",
       "113                NigerianPidginEnglish\n",
       "60     Hmong_Miao-Sichuan-Guizhou-Yunnan\n",
       "140         Runyankore-rukiga_Nkore-kiga\n",
       "22                      Campa_Pajonalino\n",
       "175                                Vlach\n",
       "112                      Ngangela_Nyemba\n",
       "116                            Norwegian\n",
       "14                        Basque_Euskara\n",
       "133                              Quechua\n",
       "104                       Mayan_Yucateco\n",
       "189                                 Zulu\n",
       "170                              Tzotzil\n",
       "69                         Iloko_Ilocano\n",
       "33                             Chickasaw\n",
       "118              Norwegian_Norsk-Nynorsk\n",
       "25                     Cashibo-Cacataibo\n",
       "97                              Malagasy\n",
       "21                            Cakchiquel\n",
       "8                                Arabela\n",
       "163                           Tojol-abal\n",
       "177                                Waray\n",
       "73                   IrishGaelic_Gaeilge\n",
       "55                  HaitianCreole_Kreyol\n",
       "135          Rarotongan_MaoriCookIslands\n",
       "142                               Samoan\n",
       "dtype: object"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "cf397aaa-fb60-462f-a1c2-949049f7cb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLM achieves accuracy 0.6 when learning the rule \"The sentence is in the language German_Deutsch\".\n",
      "The LLM achieves accuracy 0.55 when learning the rule \"The sentence is in the language Oshiwambo_Ndonga\".\n",
      "The LLM achieves accuracy 0.55 when learning the rule \"The sentence is in the language Tongan_Tonga\".\n",
      "The LLM achieves accuracy 0.6 when learning the rule \"The sentence is in the language Tenek_Huasteco\".\n",
      "The LLM achieves accuracy 0.55 when learning the rule \"The sentence is in the language Urarina\".\n",
      "The LLM achieves accuracy 0.775 when learning the rule \"The sentence is in the language NigerianPidginEnglish\".\n",
      "The LLM achieves accuracy 0.625 when learning the rule \"The sentence is in the language Hmong_Miao-Sichuan-Guizhou-Yunnan\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Runyankore-rukiga_Nkore-kiga\".\n",
      "The LLM achieves accuracy 0.725 when learning the rule \"The sentence is in the language Campa_Pajonalino\".\n",
      "The LLM achieves accuracy 0.75 when learning the rule \"The sentence is in the language Vlach\".\n",
      "The LLM achieves accuracy 0.55 when learning the rule \"The sentence is in the language Ngangela_Nyemba\".\n",
      "The LLM achieves accuracy 0.8 when learning the rule \"The sentence is in the language Norwegian\".\n",
      "The LLM achieves accuracy 0.55 when learning the rule \"The sentence is in the language Basque_Euskara\".\n",
      "The LLM achieves accuracy 0.625 when learning the rule \"The sentence is in the language Quechua\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Mayan_Yucateco\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Zulu\".\n",
      "The LLM achieves accuracy 0.625 when learning the rule \"The sentence is in the language Tzotzil\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Iloko_Ilocano\".\n",
      "The LLM achieves accuracy 0.525 when learning the rule \"The sentence is in the language Chickasaw\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Norwegian_Norsk-Nynorsk\".\n",
      "The LLM achieves accuracy 0.525 when learning the rule \"The sentence is in the language Cashibo-Cacataibo\".\n",
      "The LLM achieves accuracy 0.525 when learning the rule \"The sentence is in the language Malagasy\".\n",
      "The LLM achieves accuracy 0.675 when learning the rule \"The sentence is in the language Cakchiquel\".\n",
      "The LLM achieves accuracy 0.6 when learning the rule \"The sentence is in the language Arabela\".\n",
      "The LLM achieves accuracy 0.65 when learning the rule \"The sentence is in the language Tojol-abal\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Waray\".\n",
      "The LLM achieves accuracy 0.625 when learning the rule \"The sentence is in the language IrishGaelic_Gaeilge\".\n",
      "The LLM achieves accuracy 0.6 when learning the rule \"The sentence is in the language HaitianCreole_Kreyol\".\n",
      "The LLM achieves accuracy 0.55 when learning the rule \"The sentence is in the language Rarotongan_MaoriCookIslands\".\n",
      "The LLM achieves accuracy 0.575 when learning the rule \"The sentence is in the language Samoan\".\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for lang in test_set:\n",
    "    train_true = build_test_sentences_true(corpus, lang, train_true, test_k = 20, seed = None)\n",
    "    train_false = build_test_sentences_false(corpus, lang, train_false, test_k = 20, seed = None)\n",
    "    accuracy = evaluate_icl(corpus, lang, train_true, train_false, k_test = 20, verbose = False)\n",
    "    print('The LLM achieves accuracy {} when learning the rule \\\"The sentence is in the language {}\\\".'.format(accuracy, lang))\n",
    "    results[lang] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "e01232ca-7aa1-4d9f-b466-44b351178ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table = pd.DataFrame.from_dict(results, orient = 'index', columns = ['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "07eef352-18d4-4431-901a-ff1a704fb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table.sort_values('Accuracy', ascending = False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "bba4f763-b985-4fae-a649-c0f798a35456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Norwegian</th>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NigerianPidginEnglish</th>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vlach</th>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campa_Pajonalino</th>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cakchiquel</th>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tojol-abal</th>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quechua</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tzotzil</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hmong_Miao-Sichuan-Guizhou-Yunnan</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IrishGaelic_Gaeilge</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arabela</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenek_Huasteco</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaitianCreole_Kreyol</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German_Deutsch</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iloko_Ilocano</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waray</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norwegian_Norsk-Nynorsk</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zulu</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mayan_Yucateco</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runyankore-rukiga_Nkore-kiga</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samoan</th>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oshiwambo_Ndonga</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basque_Euskara</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ngangela_Nyemba</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urarina</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tongan_Tonga</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rarotongan_MaoriCookIslands</th>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chickasaw</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cashibo-Cacataibo</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malagasy</th>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Accuracy\n",
       "Norwegian                             0.800\n",
       "NigerianPidginEnglish                 0.775\n",
       "Vlach                                 0.750\n",
       "Campa_Pajonalino                      0.725\n",
       "Cakchiquel                            0.675\n",
       "Tojol-abal                            0.650\n",
       "Quechua                               0.625\n",
       "Tzotzil                               0.625\n",
       "Hmong_Miao-Sichuan-Guizhou-Yunnan     0.625\n",
       "IrishGaelic_Gaeilge                   0.625\n",
       "Arabela                               0.600\n",
       "Tenek_Huasteco                        0.600\n",
       "HaitianCreole_Kreyol                  0.600\n",
       "German_Deutsch                        0.600\n",
       "Iloko_Ilocano                         0.575\n",
       "Waray                                 0.575\n",
       "Norwegian_Norsk-Nynorsk               0.575\n",
       "Zulu                                  0.575\n",
       "Mayan_Yucateco                        0.575\n",
       "Runyankore-rukiga_Nkore-kiga          0.575\n",
       "Samoan                                0.575\n",
       "Oshiwambo_Ndonga                      0.550\n",
       "Basque_Euskara                        0.550\n",
       "Ngangela_Nyemba                       0.550\n",
       "Urarina                               0.550\n",
       "Tongan_Tonga                          0.550\n",
       "Rarotongan_MaoriCookIslands           0.550\n",
       "Chickasaw                             0.525\n",
       "Cashibo-Cacataibo                     0.525\n",
       "Malagasy                              0.525"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2afbcb2-c7fe-4018-82ee-838cb3244e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115214a0-16c6-403e-bc89-3149fb1a867d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
